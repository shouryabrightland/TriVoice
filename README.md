# ğŸ™ï¸ TryVoice v1

A local, offline-first voice assistant built in Python.
Designed for low-resource systems like Raspberry Pi.
No cloud. No spying. Full control.

---

## ğŸš€ Features

* ğŸ¤ **Live voice input** using Whisper (offline)
* ğŸ§  **Local LLM** via Ollama (no internet required after setup)
* ğŸ”Š **Real-time text-to-speech** using Piper (streaming, no file I/O)
* âš¡ **Low latency streaming** (LLM â†’ TTS chunk by chunk)
* ğŸ§© **Middleware architecture** (Request / Response like backend servers)
* ğŸ§  **Soft-coded intent detection** (robust to Whisper mistakes)
* ğŸ§ª **Graceful failure handling**

  * Ollama not running
  * Model downloading
  * Out-of-memory situations
* ğŸª¶ Optimized for **low RAM & CPU**

---

## ğŸ–¥ï¸ Requirements

### 1. Python

* Version: **Python 3.9+**
* Download:
  [https://www.python.org/downloads/](https://www.python.org/downloads/)

Check installation:

```bash
python --version
```

---

### 2. Ollama (Local LLM Backend)

* Download:
  [https://ollama.com/download](https://ollama.com/download)

After installing, pull a model:

```bash
ollama pull gemma3:1b
```

Start Ollama server:

```bash
ollama serve
```

âš ï¸ Ollama **must be running** before starting TryVoice.

---

## ğŸ“¦ Installation

### Create virtual environment

```bash
python -m venv venv
```

### Activate environment

Linux / macOS:

```bash
source venv/bin/activate
```

Windows (PowerShell):

```bash
venv\Scripts\Activate.ps1
```

---

### Install dependencies

```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Run the Assistant

```bash
python main.py
```

The assistant will:

1. Play startup sound
2. Initialize Whisper, Ollama, TTS
3. Start listening for voice input

---

## ğŸ§  How It Works (High Level)

```
Microphone
   â†“
Whisper (Speech â†’ Text)
   â†“
Middleware (Intent / Command handling)
   â†“
Ollama (LLM reasoning)
   â†“
Streaming Text
   â†“
Piper TTS (Live Speech Output)
```

No audio files are written during normal operation.

---

## ğŸ—£ï¸ Voice Commands (Examples)

These are handled **without calling the LLM**:

* â€œTry command shutdownâ€
* â€œTry command clear memoryâ€
* â€œYesâ€ / â€œNoâ€ confirmations
* Soft exits like â€œbyeâ€, â€œleaveâ€, â€œquitâ€

The system confirms destructive actions before executing them.

---

## âš ï¸ Known Limitations

* Whisper may mis-transcribe words
  Example:
  `try` â†’ `dry`
  `shutdown` â†’ `set down`

This is handled using:

* fuzzy keyword sets
* confidence-based intent scoring
* agent alias matching

---

## ğŸ§ª Troubleshooting

**Ollama not running**

* Assistant will respond with a safe message
* Start Ollama using:

```bash
ollama serve
```

**Model downloading**

* Assistant waits and informs the user

**Out of memory**

* Close heavy apps (browser, VS Code)
* Use smaller model like `gemma3:1b`

---

## ğŸ› ï¸ Project Status

* âœ… Version 1 complete
* ğŸ”§ Future work:

  * Wake word
  * GPIO / hardware control
  * Better noise handling
  * Multi-agent routing

---

## ğŸ“œ License

Open for learning and experimentation.
Use responsibly.
